{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Using cached albumentations-2.0.0-py3-none-any.whl (273 kB)\n",
      "Collecting eval-type-backport\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Collecting numpy>=1.24.4\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\personal documents\\mtech\\semester 4\\project\\jupytercode\\virtual\\lib\\site-packages (from albumentations) (4.12.2)\n",
      "Collecting pydantic>=2.9.2\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Collecting scipy>=1.10.0\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Collecting opencv-python-headless>=4.9.0.80\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Collecting albucore==0.0.23\n",
      "  Using cached albucore-0.0.23-py3-none-any.whl (14 kB)\n",
      "Collecting simsimd>=5.9.2\n",
      "  Using cached simsimd-6.2.1-cp39-cp39-win_amd64.whl (86 kB)\n",
      "Collecting stringzilla>=3.10.4\n",
      "  Using cached stringzilla-3.11.3-cp39-cp39-win_amd64.whl (80 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Using cached pydantic_core-2.27.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Installing collected packages: stringzilla, simsimd, PyYAML, pydantic-core, numpy, eval-type-backport, annotated-types, scipy, pydantic, opencv-python-headless, albucore, albumentations\n",
      "Successfully installed PyYAML-6.0.2 albucore-0.0.23 albumentations-2.0.0 annotated-types-0.7.0 eval-type-backport-0.2.2 numpy-2.0.2 opencv-python-headless-4.10.0.84 pydantic-2.10.5 pydantic-core-2.27.2 scipy-1.13.1 simsimd-6.2.1 stringzilla-3.11.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\personal documents\\mtech\\semester 4\\project\\jupytercode\\virtual\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install albumentations\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = {\n",
    "    0: ('Soil', (0, 0, 0)),\n",
    "    1: ('Maize', (255, 0, 0)),\n",
    "    2: ('Maize two-leaf stage', (234, 0, 0)),\n",
    "    3: ('Maize four-leaf stage', (212, 0, 0)),\n",
    "    4: ('Maize six-leaf stage', (191, 0, 0)),\n",
    "    5: ('Maize eight-leaf stage', (170, 0, 0)),\n",
    "    6: ('Maize max', (149, 0, 0)),\n",
    "    7: ('Sugar beet', (255, 85, 0)),\n",
    "    8: ('Sugar beet two-leaf stage', (234, 78, 0)),\n",
    "    9: ('Sugar beet four-leaf stage', (212, 71, 0)),\n",
    "    10: ('Sugar beet six-leaf stage', (191, 64, 0)),\n",
    "    11: ('Sugar beet eight-leaf stage', (170, 57, 0)),\n",
    "    12: ('Sugar beet Max', (149, 50, 0)),\n",
    "    13: ('Pea', (255, 170, 0)),\n",
    "    14: ('Courgette', (255, 255, 0)),\n",
    "    15: ('Pumpkins', (170, 255, 0)),\n",
    "    16: ('Radish', (85, 255, 0)),\n",
    "    17: ('Asparagus', (0, 255, 0)),\n",
    "    18: ('Potato', (0, 255, 85)),\n",
    "    19: ('Flat leaf parsley', (0, 255, 170)),\n",
    "    20: ('Curly leaf parsley', (0, 255, 255)),\n",
    "    21: ('Cowslip', (0, 170, 255)),\n",
    "    22: ('Poppy', (0, 85, 255)),\n",
    "    23: ('Hemp', (0, 0, 255)),\n",
    "    24: ('Sunflower', (85, 0, 255)),\n",
    "    25: ('Sage', (170, 0, 255)),\n",
    "    26: ('Common bean', (255, 0, 255)),\n",
    "    27: ('Faba bean', (255, 0, 170)),\n",
    "    28: ('Clover', (255, 0, 85)),\n",
    "    29: ('Hybrid goosefoot', (255, 188, 178)),\n",
    "    30: ('Black-bindweed', (255, 207, 178)),\n",
    "    31: ('Cockspur grass', (255, 226, 178)),\n",
    "    32: ('Red-root amaranth', (255, 245, 178)),\n",
    "    33: ('White goosefoot', (245, 255, 178)),\n",
    "    34: ('Thorn apple', (226, 255, 178)),\n",
    "    35: ('Potato weed', (207, 255, 178)),\n",
    "    36: ('German chamomile', (188, 255, 178)),\n",
    "    37: ('Saltbush', (178, 255, 188)),\n",
    "    38: ('Creeping thistle', (178, 255, 207)),\n",
    "    39: ('Field milk thistle', (178, 255, 226)),\n",
    "    40: ('Purslane', (178, 255, 245)),\n",
    "    41: ('Black nightshade', (178, 245, 255)),\n",
    "    42: ('Mercuries', (178, 226, 255)),\n",
    "    43: ('Spurge', (178, 207, 255)),\n",
    "    44: ('Pale persicaria', (178, 188, 255)),\n",
    "    45: ('Geraniums', (188, 178, 255)),\n",
    "    46: ('Cleavers', (207, 178, 255)),\n",
    "    47: ('Whitetop', (226, 178, 255)),\n",
    "    48: ('Meadow-grass', (245, 178, 255)),\n",
    "    49: ('Frosted orach', (255, 178, 245)),\n",
    "    50: ('Black horehound', (255, 178, 226)),\n",
    "    51: ('Shepherds purse', (255, 178, 207)),\n",
    "    52: ('Field bindweed', (255, 178, 188)),\n",
    "    53: ('Common mugwort', (255, 194, 178)),\n",
    "    54: ('Hedge mustard', (255, 213, 178)),\n",
    "    55: ('Groundsel', (255, 219, 178)),\n",
    "    56: ('Speedwell', (255, 232, 178)),\n",
    "    57: ('Broadleaf plantain', (255, 238, 178)),\n",
    "    58: ('White ball-mustard', (255, 251, 178)),\n",
    "    59: ('Peppermint', (255, 212, 0)),\n",
    "    60: ('Field pennycress', (239, 255, 178)),\n",
    "    61: ('Corn spurry', (233, 255, 178)),\n",
    "    62: ('Purple crabgrass', (220, 255, 178)),\n",
    "    63: ('Common fumitory', (214, 255, 178)),\n",
    "    64: ('Ivy-leaved speedwell', (201, 255, 178)),\n",
    "    65: ('Annual meadow grass', (195, 255, 178)),\n",
    "    66: ('Redshank', (182, 255, 178)),\n",
    "    67: ('Common hemp-nettle', (178, 255, 194)),\n",
    "    68: ('Rough meadow-grass', (178, 255, 200)),\n",
    "    69: ('Green bristlegrass', (178, 255, 213)),\n",
    "    70: ('Small geranium', (178, 255, 220)),\n",
    "    71: ('Cornflower', (178, 255, 232)),\n",
    "    72: ('Common corn-cockle', (178, 255, 238)),\n",
    "    73: ('Creeping crowfoot', (178, 255, 251)),\n",
    "    74: ('Wall barley', (178, 239, 255)),\n",
    "    75: ('Annual fescue', (178, 233, 255)),\n",
    "    76: ('Purple dead-nettle', (178, 220, 255)),\n",
    "    77: ('Ribwort plantain', (178, 214, 255)),\n",
    "    78: ('Pineappleweed', (178, 201, 255)),\n",
    "    79: ('Common chickweed', (178, 195, 255)),\n",
    "    80: ('Hedge mustard', (178, 182, 255)),\n",
    "    81: ('Soft brome', (194, 178, 255)),\n",
    "    82: ('Wild pansy', (200, 178, 255)),\n",
    "    83: ('Yellow rocket', (213, 178, 255)),\n",
    "    84: ('Common wild oat', (219, 178, 255)),\n",
    "    85: ('Red poppy', (232, 178, 255)),\n",
    "    86: ('Rye brome', (238, 178, 255)),\n",
    "    87: ('Knotgrass', (251, 178, 255)),\n",
    "    88: ('Prickly lettuce', (255, 178, 239)),\n",
    "    89: ('Copse-bindweed', (255, 178, 233)),\n",
    "    90: ('Manyseeds', (255, 178, 220)),\n",
    "    91: ('Common buckwheat', (255, 178, 214)),\n",
    "    92: ('Chives', (212, 255, 0)),\n",
    "    93: ('Garlic', (127, 255, 0)),\n",
    "    94: ('Soybean', (42, 255, 0)),\n",
    "    95: ('Wild carrot', (244, 255, 0)),\n",
    "    96: ('Field mustard', (159, 255, 0)),\n",
    "    97: ('Giant fennel', (74, 255, 0)),\n",
    "    98: ('Common horsetail', (10, 255, 0)),\n",
    "    99: ('Common dandelion', (202, 255, 0)),\n",
    "    255: ('Vegetation', (128, 128, 128))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMAGE_DIR = \"./splitDataset/test/images/\"\n",
    "ANNOTATION_DIR = \"./splitDataset/test/labels/\"\n",
    "OUTPUT_IMAGE_DIR = \"./splitDataset/augmentated/images/\"\n",
    "OUTPUT_ANNOTATION_DIR = \"./splitDataset/augmentated/test/labels/\"\n",
    "OUTPUT_VISUALS = \"./splitDataset/augmentated/visuals/\"\n",
    "NUM_AUGMENTATIONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_ANNOTATION_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_VISUALS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\validation.py:45: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "c:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\pydantic\\main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `dict[str, any]` but got `UniformParams` with value `UniformParams(noise_type=...6, 0.0784313725490196)])` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# Define the augmentations (same as before)\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=0.3),\n",
    "    A.Blur(blur_limit=3, p=0.3),\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])) #Important for YOLO format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image_path, annotation_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:  # Check if the line has the expected format\n",
    "                class_id = int(parts[0])\n",
    "                x_center = float(parts[1])\n",
    "                y_center = float(parts[2])\n",
    "                width = float(parts[3])\n",
    "                height = float(parts[4])\n",
    "\n",
    "                # Convert YOLO format to xmin, ymin, xmax, ymax\n",
    "                xmin = int((x_center - width / 2) * img_width)\n",
    "                ymin = int((y_center - height / 2) * img_height)\n",
    "                xmax = int((x_center + width / 2) * img_width)\n",
    "                ymax = int((y_center + height / 2) * img_height)\n",
    "\n",
    "                bboxes.append([x_center, y_center, width, height])\n",
    "                class_labels.append(class_id)\n",
    "            else:\n",
    "                print(f\"Invalid line in annotation file: {line.strip()} in {annotation_path}\")\n",
    "\n",
    "    for i in range(NUM_AUGMENTATIONS):\n",
    "        transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "        transformed_class_labels = transformed['class_labels']\n",
    "\n",
    "        transformed_image = cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        image_name = os.path.basename(image_path).split(\".\")[0]\n",
    "        annotation_name = os.path.basename(annotation_path).split(\".\")[0]\n",
    "\n",
    "        output_image_path = os.path.join(OUTPUT_IMAGE_DIR, f\"{image_name}_aug_{i}.jpg\")\n",
    "        output_annotation_path = os.path.join(OUTPUT_ANNOTATION_DIR, f\"{annotation_name}_aug_{i}.txt\")\n",
    "\n",
    "        cv2.imwrite(output_image_path, transformed_image)\n",
    "\n",
    "        with open(output_annotation_path, 'w') as outfile:\n",
    "            for j in range(len(transformed_bboxes)):\n",
    "                #Convert back to YOLO format\n",
    "                x_center = ((transformed_bboxes[j][0] + transformed_bboxes[j][2]) / 2) / img_width\n",
    "                y_center = ((transformed_bboxes[j][1] + transformed_bboxes[j][3]) / 2) / img_height\n",
    "                width = (transformed_bboxes[j][2] - transformed_bboxes[j][0]) / img_width\n",
    "                height = (transformed_bboxes[j][3] - transformed_bboxes[j][1]) / img_height\n",
    "                outfile.write(f\"{transformed_class_labels[j]} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "    print(f\"Augmented {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "In YOLO format all coordinates must be float and in range (0, 1], got [[950. 665. 974. 689.   2.]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./YOLO/images/ave-0041-0015.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m annotation_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./YOLO/lables/ave-0041-0015.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43maugment_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[82], line 31\u001b[0m, in \u001b[0;36maugment_image\u001b[1;34m(image_path, annotation_path)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid line in annotation file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mannotation_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_AUGMENTATIONS):\n\u001b[1;32m---> 31\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     transformed_image \u001b[38;5;241m=\u001b[39m transformed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     33\u001b[0m     transformed_bboxes \u001b[38;5;241m=\u001b[39m transformed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\composition.py:439\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m need_to_run:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m    442\u001b[0m     data \u001b[38;5;241m=\u001b[39m t(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\composition.py:451\u001b[0m, in \u001b[0;36mCompose.preprocess\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess input data before applying transforms.\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(data)\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_processors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_arrays(data)\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\composition.py:478\u001b[0m, in \u001b[0;36mCompose._preprocess_processors\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    476\u001b[0m     processor\u001b[38;5;241m.\u001b[39mensure_data_valid(data)\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m--> 478\u001b[0m     \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\utils.py:208\u001b[0m, in \u001b[0;36mDataProcessor.preprocess\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    206\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_label_fields_to_data(data)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_fields) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m--> 208\u001b[0m     data[data_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\utils.py:222\u001b[0m, in \u001b[0;36mDataProcessor.check_and_convert\u001b[1;34m(self, data, shape, direction)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m    220\u001b[0m process_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_albumentations \u001b[38;5;28;01mif\u001b[39;00m direction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_from_albumentations\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\bbox_utils.py:157\u001b[0m, in \u001b[0;36mBboxProcessor.convert_to_albumentations\u001b[1;34m(self, data, shape)\u001b[0m\n\u001b[0;32m    154\u001b[0m     check_bboxes(data_np)\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_np\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_bboxes_to_albumentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_validity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\augmentations\\utils.py:190\u001b[0m, in \u001b[0;36mhandle_empty_array.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(array) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\virtual\\lib\\site-packages\\albumentations\\core\\bbox_utils.py:289\u001b[0m, in \u001b[0;36mconvert_bboxes_to_albumentations\u001b[1;34m(bboxes, source_format, shape, check_validity)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m source_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_validity \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((bboxes[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m (bboxes[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m--> 289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn YOLO format all coordinates must be float and in range (0, 1], got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbboxes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    291\u001b[0m     w_half, h_half \u001b[38;5;241m=\u001b[39m bboxes[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, bboxes[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    292\u001b[0m     converted_bboxes[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m bboxes[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m w_half  \u001b[38;5;66;03m# x_min\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: In YOLO format all coordinates must be float and in range (0, 1], got [[950. 665. 974. 689.   2.]]"
     ]
    }
   ],
   "source": [
    "image_path = './YOLO/images/ave-0041-0015.jpg'\n",
    "annotation_path = './YOLO/lables/ave-0041-0015.txt'\n",
    "augment_image(image_path, annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bounding_box(image_path, box_path, visual_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    bboxes = []\n",
    "    with open(box_path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(float(parts[0]))  # Class ID\n",
    "            center_x = float(parts[1])  # Center X\n",
    "            center_y = float(parts[2])  # Center Y\n",
    "            width = float(parts[3])  # Width\n",
    "            height = float(parts[4])  # Height\n",
    "            bboxes.append((class_id, center_x, center_y, width, height))\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        class_id, center_x, center_y, width, height = bbox\n",
    "        \n",
    "        # Convert YOLO format to pixel values\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        left = int((center_x - width / 2) * (img_width))\n",
    "        top = int((center_y - height / 2) * img_height)\n",
    "        right = int((center_x + width / 2) * img_width)\n",
    "        bottom = int((center_y + height / 2) * img_height)\n",
    "\n",
    "        label, color = label_data.get(class_id)\n",
    "\n",
    "        print((left, top), (right, bottom), (center_x - width, center_y- height, width, height))\n",
    "\n",
    "        # Draw the rectangle\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), color, 2)  # Green rectangle\n",
    "        # Add label text\n",
    "        cv2.putText(image, label, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,color, 2)\n",
    "\n",
    "    print(visual_path)\n",
    "    cv2.imwrite(visual_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) (0, 0) (0.000415726162706657, 0.0009157431358129115, -0.00027158347559937585, -0.0005933221631601234)\n",
      "././splitDataset/augmentated/visuals/ave-0041-0015_aug_2.jpg\n"
     ]
    }
   ],
   "source": [
    "# image_name = key\n",
    "image_path_ = '.\\\\splitDataset\\\\augmentated\\\\images\\\\ave-0041-0015_aug_1.jpg'\n",
    "box_path_ = '.\\\\splitDataset\\\\augmentated\\\\test\\\\labels\\\\ave-0041-0015_aug_1.txt'\n",
    "vis_path = './' +OUTPUT_VISUALS+ 'ave-0041-0015_aug_2'+'.jpg'\n",
    "visualize_bounding_box(image_path_, box_path_, vis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python==4.5.4.60\n",
      "  Downloading opencv_python-4.5.4.60-cp39-cp39-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\personal documents\\mtech\\semester 4\\project\\jupytercode\\.venv\\lib\\site-packages (from opencv-python==4.5.4.60) (2.0.2)\n",
      "Downloading opencv_python-4.5.4.60-cp39-cp39-win_amd64.whl (35.1 MB)\n",
      "   ---------------------------------------- 0.0/35.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/35.1 MB 52.4 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 2.1/35.1 MB 6.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.2/35.1 MB 7.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.2/35.1 MB 6.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.2/35.1 MB 6.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.2/35.1 MB 6.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 6.3/35.1 MB 4.7 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 7.3/35.1 MB 4.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 7.3/35.1 MB 4.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 7.3/35.1 MB 4.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 9.4/35.1 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 10.5/35.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 11.5/35.1 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 11.5/35.1 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 11.5/35.1 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 11.5/35.1 MB 4.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 13.6/35.1 MB 3.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 13.6/35.1 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 14.7/35.1 MB 3.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 14.7/35.1 MB 3.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 15.7/35.1 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 16.8/35.1 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 16.8/35.1 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 16.8/35.1 MB 3.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 18.4/35.1 MB 3.4 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 19.9/35.1 MB 3.7 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 21.0/35.1 MB 3.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 21.0/35.1 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 22.0/35.1 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 23.1/35.1 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 24.1/35.1 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 24.1/35.1 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 24.1/35.1 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 24.1/35.1 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 24.1/35.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 25.2/35.1 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 26.2/35.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 26.2/35.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 26.2/35.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 27.3/35.1 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 27.3/35.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 28.3/35.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 28.3/35.1 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 28.3/35.1 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 29.4/35.1 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 29.4/35.1 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 30.4/35.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 30.4/35.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 31.5/35.1 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 33.6/35.1 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 33.8/35.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 35.1/35.1 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.10.0.84\n",
      "    Uninstalling opencv-python-4.10.0.84:\n",
      "      Successfully uninstalled opencv-python-4.10.0.84\n",
      "Successfully installed opencv-python-4.5.4.60\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Personal Documents\\Mtech\\semester 4\\Project\\JupyterCode\\.venv\\Lib\\site-packages\\~-2'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ultralytics 8.3.61 requires opencv-python>=4.6.0, but you have opencv-python 4.5.4.60 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python==4.5.4.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
